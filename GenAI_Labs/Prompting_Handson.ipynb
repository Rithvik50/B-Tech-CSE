{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_6gH6K81Brr"
      },
      "source": [
        "## Prompting Handson: Zero Shot, Few Shot, Chain of Thought and ReAct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM5N9Dyi0-ZQ"
      },
      "source": [
        "\n",
        "## 1. Setup\n",
        "Install and import necessary libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhDyFKrDzx-Y",
        "outputId": "07acdf9e-6825-4f9b-84af-e49b3835d933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq python-dotenv\n",
        "\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMKEz6Wj3AS8"
      },
      "source": [
        "# 2. Zero Shot and Few Shot\n",
        "\n",
        "What's a shot üò∂?\n",
        "\n",
        "In machine learning, specifically in Few-shot and Zero-shot learning, a **\"shot\" refers to an example provided to the model to help it understand the task.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlwQ4-6-3JMV"
      },
      "source": [
        "# Let's look at an analogy:\n",
        "Imagine you're teaching someone how to drive a car.\n",
        "\n",
        "# **Zero-Shot Prompting (No Examples Given)**\n",
        "\n",
        "  üí° Scenario: You hand the car keys to a person who has never driven before and say:\n",
        "  \"Drive to the grocery store.\"\n",
        "\n",
        "  üîç What happens?\n",
        "\n",
        "  If they‚Äôve never driven before, they‚Äôll struggle.\n",
        "  If they‚Äôve seen others drive, they might guess how to do it, but mistakes are likely.\n",
        "\n",
        "  üí° AI Equivalent:\n",
        "\n",
        "  The model is asked to generate an answer without any examples.\n",
        "  It relies on what it has already learned during training.\n",
        "\n",
        "# **Few-Shot Prompting (Providing Examples Before Asking)**\n",
        "\n",
        "  üí° Scenario: Before giving them the keys, you drive them to the grocery store a few times and explain each step:\n",
        "  \"First, start the car. Then, press the gas slowly. Stop at red lights‚Ä¶\"\n",
        "\n",
        "  üîç What happens?\n",
        "\n",
        "  They learn by observing and following patterns.\n",
        "  When asked to drive, they can replicate the process more accurately.\n",
        "\n",
        "  üí° AI Equivalent:\n",
        "\n",
        "  The model is given a few examples before being asked to generate a response.\n",
        "  It understands the pattern and performs better than in zero-shot prompting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UStEiMXB4Moo"
      },
      "source": [
        "**SUMMARY**\n",
        " ### Zero-Shot Learning\n",
        "- Model solves task without any examples\n",
        "\n",
        "- Relies entirely on pre-trained knowledge\n",
        "\n",
        "- Example: \"Classify this text as positive or negative: {text}\"\n",
        "\n",
        "### Few-Shot Learning\n",
        "- Model is given 2-5 examples before the target task\n",
        "\n",
        "- Helps establish pattern/format\n",
        "\n",
        "- Example: \"Apple -> fruit, Carrot -> vegetable, Potato -> ?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "cSSZHWIu4qH-"
      },
      "outputs": [],
      "source": [
        "def prompt_groq(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",  # Choose your model\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2k6QHpp4u-7"
      },
      "source": [
        "## 1. **Zero-Shot Prompting Example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiDOhOcp4_0A",
        "outputId": "3cb0ea37-5831-4d7f-bf4e-15afcf6f38db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-Shot Result:\n",
            " The translation of \"Bonjour, comment √ßa va?\" into English is:\n",
            "\n",
            "\"Hello, how are you?\"\n"
          ]
        }
      ],
      "source": [
        "zero_shot_prompt = \"Translate the sentence 'Bonjour, comment √ßa va?' into English.\"  # You can try translating this to other languages too!\n",
        "zero_shot_result = prompt_groq(zero_shot_prompt)\n",
        "print(\"Zero-Shot Result:\\n\", zero_shot_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Un8y9VAyXZ",
        "outputId": "7322565e-b9ba-4779-f236-20eff2d23072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-Shot Result:\n",
            " A straightforward one!\n",
            "\n",
            "This sentence is POSITIVE! The use of the word \"absolutely\" and \"love\" convey a strong, enthusiastic sentiment, indicating a highly positive opinion about the new phone.\n"
          ]
        }
      ],
      "source": [
        "zero_shot_prompt2=\" Classify if this sentence is positive, negative or neutral 'I absolutely love this new phone!' \"\n",
        "zero_shot_result2 = prompt_groq(zero_shot_prompt2)\n",
        "print(\"Zero-Shot Result:\\n\", zero_shot_result2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1LNUuKtBMMx"
      },
      "source": [
        "## 2. **Few-Shot Prompting Example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywTfkB8M0jZP",
        "outputId": "8d45be84-3853-4031-d607-8026642b34ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Few-Shot Result:\n",
            " English: \"I am a student.\"\n"
          ]
        }
      ],
      "source": [
        "few_shot_prompt = \"\"\"\n",
        "Translate the following French sentences to English:\n",
        "French: \"Bonjour, comment √ßa va?\"\n",
        "English: \"Hello, how are you?\"\n",
        "\n",
        "French: \"Merci beaucoup!\"\n",
        "English: \"Thank you very much!\"\n",
        "\n",
        "French: \"Je suis √©tudiant.\"\n",
        "English:\n",
        "\"\"\"\n",
        "few_shot_result = prompt_groq(few_shot_prompt)\n",
        "print(\"\\nFew-Shot Result:\\n\", few_shot_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhhvuA_KBlbz"
      },
      "source": [
        "#  3. Chain of Thought (CoT)\n",
        "\n",
        "What is Chain of Thought?\n",
        "\n",
        "Chain of Thought (CoT) is a prompting technique where the model is guided to solve a problem step-by-step, mimicking human reasoning. It is particularly useful for complex tasks like arithmetic, logic, and planning.\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "### Chain-of-Thought (CoT)\n",
        "- Explicit step-by-step reasoning demonstration\n",
        "\n",
        "- Combines few-shot with reasoning steps\n",
        "\n",
        "- Especially useful for complex problems\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Example: Solving a Math Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6iPIofPBVNY",
        "outputId": "7c91f9f3-cc2b-4fb7-9a50-79ff657abf15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Chain of Thought Result:\n",
            " Here are the step-by-step solution:\n",
            "\n",
            "Step 1: John starts with 3 apples.\n",
            "\n",
            "Step 2: He buys 5 more apples. Now he has 3 + 5 = 8 apples.\n",
            "\n",
            "Step 3: He gives 2 apples to his friend. To find the number of apples John has now, we subtract 2 from 8:\n",
            "\n",
            "8 - 2 = 6\n",
            "\n",
            "Therefore, John has 6 apples now.\n"
          ]
        }
      ],
      "source": [
        "cot_prompt = \"\"\"\n",
        "Solve the following math problem step by step:\n",
        "\n",
        "Question: John has 3 apples. He buys 5 more apples and gives 2 to his friend. How many apples does he have now?\n",
        "\n",
        "Step 1: John starts with 3 apples.\n",
        "Step 2: He buys 5 more apples. Now he has 3 + 5 = 8 apples.\n",
        "Step 3: He gives 2 apples to his friend. Now he has\n",
        "\"\"\"\n",
        "cot_result = prompt_groq(cot_prompt)\n",
        "print(\"\\nChain of Thought Result:\\n\", cot_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_ptfAtv4TiC"
      },
      "source": [
        "##4. Graph-of-Thought\n",
        "\n",
        "Graph of Thoughts (GoT) is a reasoning framework where multiple solution paths are explored simultaneously and compared before reaching a final decision. Unlike linear approaches (like CoT), GoT enables a model to analyze multiple aspects of a problem in parallel and dynamically connect different ideas to form an optimized solution.\n",
        "\n",
        "Example:\n",
        "A model evaluating different investment strategies based on factors like risk, return, and market trends, allowing it to assess multiple possibilities before recommending the best approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pqH1hFbv1wK",
        "outputId": "d6dd7d44-cf58-4af5-d1aa-e25c2c091398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph of Thoughts Result:\n",
            " Let's evaluate each destination based on the three factors:\n",
            "\n",
            "**Japan**\n",
            "\n",
            "* **Budget:** Moderate (Accommodation and food can be affordable, but airfare and transportation can be expensive. Average daily expenses: $100-150 per person)\n",
            "* **Weather:** Spring (March-May) and autumn (September-November) are the best seasons to visit Japan, with mild temperatures and fewer crowds. Summer can be hot and humid, while winters are cold and snowy.\n",
            "* **Cultural experiences:** Japan offers a rich cultural heritage, with numerous temples, shrines, and castles to explore. Visitors can experience traditional Japanese customs, such as the tea ceremony, kimono dressing, and sumo wrestling. Must-visit places include Tokyo, Kyoto, Osaka, and Hiroshima.\n",
            "\n",
            "**Italy**\n",
            "\n",
            "* **Budget:** Affordable to Moderate (Accommodation and food can be affordable, especially outside of peak season. Airfare and transportation can be moderately priced. Average daily expenses: $80-120 per person)\n",
            "* **Weather:** Italy has a Mediterranean climate, with mild winters and warm summers. The best time to visit is spring (April-June) or autumn (September-November), when the weather is pleasant and there are fewer tourists.\n",
            "* **Cultural experiences:** Italy is renowned for its art, architecture, and history. Visitors can explore iconic landmarks like the Colosseum, Roman Forum, and Pantheon in Rome. Florence, Venice, and Tuscany offer a glimpse into the country's rich artistic and cultural heritage.\n",
            "\n",
            "**Australia**\n",
            "\n",
            "* **Budget:** Moderate to Expensive (Accommodation and food can be pricey, especially in major cities. Airfare and transportation can be moderately priced. Average daily expenses: $120-180 per person)\n",
            "* **Weather:** Australia has a diverse climate, ranging from tropical in the north to temperate in the south. The best time to visit is during the southern hemisphere's spring (September-November) and autumn (March-May), when the weather is mild and sunny.\n",
            "* **Cultural experiences:** Australia is a melting pot of cultures, with a strong Indigenous heritage and a vibrant arts scene. Visitors can explore iconic landmarks like the Sydney Opera House and Harbour Bridge, as well as the Great Barrier Reef and vast outback.\n",
            "\n",
            "Now, let's analyze the options in parallel:\n",
            "\n",
            "* **Budget:** Japan and Italy are relatively more affordable options, while Australia is the most expensive.\n",
            "* **Weather:** All three destinations have mild winters and warm summers, but Japan's spring and autumn seasons are particularly appealing.\n",
            "* **Cultural experiences:** Japan offers a unique cultural experience, with a rich history and tradition. Italy is famous for its art, architecture, and history. Australia provides a mix of Indigenous culture, modern city life, and natural beauty.\n",
            "\n",
            "Based on these factors, I would choose **Japan** as my final destination. While Japan may be slightly more expensive than Italy, its unique cultural experiences and seasonal weather make it the most appealing option. Japan's rich history, traditional customs, and modern city life offer a well-rounded experience that is hard to find elsewhere. Additionally, Japan's compact size and efficient public transportation system make it easy to explore the country without breaking the bank.\n",
            "\n",
            "Italy is a close second, with its rich artistic and cultural heritage, delicious food, and picturesque landscapes. However, Japan's unique cultural experiences and pleasant weather during the spring and autumn seasons give it a slight edge.\n",
            "\n",
            "Australia, while offering a unique cultural experience and stunning natural beauty, is the most expensive option. While it's still a great destination, it's not as budget-friendly as Japan or Italy.\n"
          ]
        }
      ],
      "source": [
        "got_prompt = \"\"\"You are planning a one-week vacation and need to decide between visiting Japan, Italy, or Australia.\n",
        "Evaluate each destination based on three factors:\n",
        "- Budget\n",
        "- Weather\n",
        "- Cultural experiences.\n",
        "Analyze all options in parallel and justify your final choice.\"\"\"\n",
        "got_result = prompt_groq(got_prompt)\n",
        "print(\"Graph of Thoughts Result:\\n\", got_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq0w8DDK3_vc"
      },
      "source": [
        "##5. Tree-of-Thought\n",
        "Tree of Thoughts (ToT) is a structured problem-solving approach where a model breaks a task into hierarchical steps, evaluates possible solutions at each level, and chooses the most optimal path. Unlike GoT, which considers multiple ideas in parallel, ToT follows a decision tree format, where each step influences the next.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVAMG3Hy3kA_",
        "outputId": "3ef2d031-3005-4597-f999-4c4c71db3e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tree of Thoughts Result:\n",
            " Here's a step-by-step analysis of the startup's options:\n",
            "\n",
            "**Step 1: Analyze potential challenges**\n",
            "\n",
            "* Fitness tracker:\n",
            "\t+ Challenges: High competition from established apps like Fitbit and MyFitnessPal, requires users to wear a device or track their activities manually, and has limited appeal to users who are not fitness enthusiasts.\n",
            "* Budgeting tool:\n",
            "\t+ Challenges: Users may not be willing to share their financial information, requires users to regularly update their expenses, and may not be effective for users with complex financial situations.\n",
            "* Social networking app:\n",
            "\t+ Challenges: High competition from established social media platforms like Facebook, Instagram, and Twitter, requires users to maintain a consistent presence to attract and retain followers, and may not be suitable for users who are not interested in social networking.\n",
            "\n",
            "**Step 2: Evaluate market demand**\n",
            "\n",
            "* Fitness tracker:\n",
            "\t+ Demand: Strong demand, especially among younger generations, with a projected market size of $82.3 billion by 2022.\n",
            "\t+ Target audience: Health-conscious individuals, fitness enthusiasts, and those with chronic health conditions.\n",
            "* Budgeting tool:\n",
            "\t+ Demand: Moderate demand, with a growing trend towards personal finance management, but still a niche market.\n",
            "\t+ Target audience: Individuals aged 25-45, families, and small business owners.\n",
            "* Social networking app:\n",
            "\t+ Demand: High demand, with over 3.8 billion active social media users worldwide, but highly competitive market.\n",
            "\t+ Target audience: Diverse range of users, including individuals, businesses, and organizations.\n",
            "\n",
            "**Step 3: Compare revenue models**\n",
            "\n",
            "* Fitness tracker:\n",
            "\t+ In-app purchases for premium features, subscription-based model for personalized coaching, or advertising partnerships with fitness brands.\n",
            "\t+ Potential revenue: $1 million to $5 million per year.\n",
            "* Budgeting tool:\n",
            "\t+ Freemium model with basic features for free, premium features for a subscription fee, or advertising partnerships with financial institutions.\n",
            "\t+ Potential revenue: $500,000 to $2 million per year.\n",
            "* Social networking app:\n",
            "\t+ Advertising-based model, sponsored content, or in-app purchases for premium features.\n",
            "\t+ Potential revenue: $5 million to $50 million per year.\n",
            "\n",
            "**Step 4: Choose the best option and justify the decision**\n",
            "\n",
            "Based on the analysis, the startup should choose the fitness tracker option. Here's why:\n",
            "\n",
            "* Strong demand: The fitness tracking market is growing rapidly, and the demand for such an app is high.\n",
            "* Competitive advantage: While there are established fitness apps, the startup can differentiate itself by offering a unique feature set, such as AI-powered coaching or personalized nutrition planning.\n",
            "* Revenue potential: The potential revenue from a fitness tracker app is significant, with a projected annual revenue of $1 million to $5 million.\n",
            "* Less competition: Compared to social networking apps, fitness tracking apps have fewer established players, making it easier for the startup to gain traction.\n",
            "\n",
            "In conclusion, while all three options have potential, the startup should choose the fitness tracker option due to its strong demand, competitive advantage, and significant revenue potential.\n"
          ]
        }
      ],
      "source": [
        "tot_prompt = \"\"\"A startup wants to launch a new mobile app. They have three options: a fitness tracker, a budgeting tool, and a social networking app.\n",
        "Step 1: Analyze potential challenges.\n",
        "Step 2: Evaluate market demand.\n",
        "Step 3: Compare revenue models.\n",
        "Step 4: Choose the best option and justify the decision.\"\"\"\n",
        "tot_result = prompt_groq(tot_prompt)\n",
        "print(\"Tree of Thoughts Result:\\n\", tot_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4RhLKrMB0_-"
      },
      "source": [
        "# 6. ReAct (Reasoning + Acting)\n",
        "\n",
        "### What is ReAct?\n",
        "ReAct combines Reasoning and Acting to enable models to interact with external tools (e.g., APIs, databases) while reasoning through a problem. It is particularly useful for tasks requiring dynamic information retrieval.\n",
        "\n",
        "Example: Using ReAct to Answer a Question\n",
        "\n",
        "\n",
        "Let‚Äôs simulate a ReAct workflow where the model retrieves information from an external API.\n",
        "\n",
        "This is the fundamental basis of AI Agents (Thinking + Action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3Bf002FBjlL",
        "outputId": "9cf213f7-151d-42a6-9175-d6e80479db32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the step-by-step process to convert the speed of light from m/s to km/h:\n",
            "\n",
            "Thought: The query requires converting the speed of light from meters per second (m/s) to kilometers per hour (km/h). To do this, I need to know the speed of light in m/s and the conversion factor from m/s to km/h.\n",
            "\n",
            "Action: search(\"speed of light in m/s\")\n",
            "Observation: The speed of light in vacuum is approximately 299,792,458 m/s.\n",
            "\n",
            "Thought: Now that I have the speed of light in m/s, I need to convert it to km/h. I can use the convert tool to do this.\n",
            "\n",
            "Action: convert(299,792,458, \"m/s\", \"km/h\")\n",
            "Observation: The speed of light in km/h is approximately 1,079,252,808 km/h.\n",
            "\n",
            "Verification: To verify the result, I can use the calculate tool to perform the conversion manually. 1 kilometer is equal to 1000 meters, and 1 hour is equal to 3600 seconds. So, I can convert the speed of light from m/s to km/h as follows: (299,792,458 m/s) √ó (1 km / 1000 m) √ó (3600 s / 1 h) ‚âà 1,079,252,808 km/h.\n",
            "\n",
            "Final Answer: The speed of light is approximately 1,079,252,808 km/h.\n"
          ]
        }
      ],
      "source": [
        "def react(query: str) -> str:\n",
        "    prompt = f\"\"\"Answer using the ReAct format with available tools:\n",
        "\n",
        "    Tools:\n",
        "    - search: General knowledge lookup\n",
        "    - calculate: Math operations\n",
        "    - convert: Unit conversions\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Step-by-Step Process:\n",
        "    1. Analyze query requirements\n",
        "    2. Identify needed information\n",
        "    3. Choose appropriate tools\n",
        "    4. Execute actions sequentially\n",
        "    5. Validate intermediate results\n",
        "    6. Formulate final answer\n",
        "\n",
        "    Follow this template:\n",
        "    Thought: [Detailed reasoning]\n",
        "    Action: [Tool call]\n",
        "    Observation: [Tool response]\n",
        "    ...repeat...\n",
        "    Verification: [Cross-check results]\n",
        "    Final Answer: [Concise answer]\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-70b-8192\",\n",
        "        temperature=0.3,\n",
        "        max_tokens=600\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Test\n",
        "print(react(\"Convert the speed of light from m/s to km/h\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcbr5KfVCLSl"
      },
      "source": [
        "#### Explanation\n",
        "- The model reasons through the problem and interacts with an external tool (API) to retrieve information.\n",
        "\n",
        "- This approach is useful for tasks requiring up-to-date or external data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YBl8HDbCNHJ"
      },
      "source": [
        "## 5. Comparison of CoT, and ReAct\n",
        "\n",
        "| Method | Description | Use Case |\n",
        "|--------|-------------|-----------|\n",
        "| Chain of Thought | Linear step-by-step reasoning | Arithmetic, logic, planning |\n",
        "| ReAct | Combines reasoning with external actions (e.g., API calls) | Dynamic information retrieval |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zuu8P9mFLke"
      },
      "source": [
        "##**Assignment Task**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSsenUEcEMS_"
      },
      "source": [
        "\n",
        "#### **1Ô∏è. Zero-Shot Prompting**  \n",
        "**Q:** Classify the sentiment of this sentence: 'The service at the restaurant was incredibly slow and disappointing.' as positive, negative, or neutral.\n",
        "\n",
        "\n",
        "\n",
        "#### **2Ô∏è. Few-Shot Prompting**  \n",
        "**Q:** Identify the language of this sentence: 'Das Wetter ist heute sch√∂n.'\n",
        "- **Examples:**  \n",
        "  - 'Bonjour, comment √ßa va?' is French  \n",
        "  - 'Hola, ¬øc√≥mo est√°s?' is Spanish\n",
        "  - 'Guten Tag, wie geht es Ihnen?' is German\n",
        "\n",
        "\n",
        "\n",
        "#### **3Ô∏è. Chain of Thought (CoT) Prompting**  \n",
        "**Q:** A train travels at 60 km/h for 2 hours, then at 80 km/h for 3 hours. What is the total distance traveled? Show your calculations step by step.\n",
        "\n",
        "\n",
        "#### **4. Graph of Thought (GoT) Prompting**  \n",
        "**Q:** You are designing an AI debate assistant that helps users form strong arguments on controversial topics (e.g., \"Should AI replace human jobs?\"). The AI must consider multiple perspectives before generating a well-balanced argument.\n",
        "\n",
        "Question:\n",
        "\n",
        "Create a GoT-based prompt that enables the AI to simultaneously evaluate multiple viewpoints (e.g., economic, ethical, social, technological) before forming an answer.\n",
        "Ensure that the model dynamically connects different perspectives rather than following a single train of thought.\n",
        "\n",
        "#### **5. Train of Thought (GoT) Prompting**  \n",
        "**Q:** You are building an AI story generator that creates mystery stories by gradually revealing clues.\n",
        "\n",
        "Question:\n",
        "\n",
        "Create a ToT-based prompt that makes the AI:\n",
        "Set up a compelling mystery scenario\n",
        "Introduce characters and possible suspects step by step\n",
        "Reveal clues progressively, eliminating false leads\n",
        "Conclude with a logical and satisfying resolution\n",
        "\n",
        "\n",
        "#### **6. ReAct Prompting**  \n",
        "**Q:** Retrieve the real-time stock price of Apple Inc. (AAPL). Analyze its recent trend to determine whether the stock is rising or falling. Based on the trend, decide whether it is a good time to buy, sell, or hold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuKoT0urPs_M",
        "outputId": "d1ae8e52-ba89-4f7b-a544-ea7673859dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "Zero-Shot Result:\n",
            " I would classify the sentiment of this sentence as negative. The use of the words \"incredibly slow\" and \"disappointing\" convey a sense of dissatisfaction and frustration with the service at the restaurant.\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Zero-Shot Prompting\n",
        "print(\"-----------------------------------------\")\n",
        "zero_shot_prompt = \"\"\"\n",
        "Classify the sentiment of this sentence as positive, negative, or neutral:\n",
        "\"The service at the restaurant was incredibly slow and disappointing.\"\n",
        "\"\"\"\n",
        "zero_shot_result = prompt_groq(zero_shot_prompt)\n",
        "print(\"Zero-Shot Result:\\n\", zero_shot_result)\n",
        "print(\"-----------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPGC_RXvPuP6",
        "outputId": "e0661f92-b8a1-4b09-b56a-f0c45ac585f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "Few-Shot Result:\n",
            " The language of the sentence \"Das Wetter ist heute sch√∂n\" is German.\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Few-Shot Prompting\n",
        "print(\"-----------------------------------------\")\n",
        "few_shot_prompt = \"\"\"\n",
        "Identify the language of this sentence: \"Das Wetter ist heute sch√∂n.\"\n",
        "Examples:\n",
        "- \"Bonjour, comment √ßa va?\" is French\n",
        "- \"Hola, ¬øc√≥mo est√°s?\" is Spanish\n",
        "- \"Guten Tag, wie geht es Ihnen?\" is German\n",
        "\"\"\"\n",
        "few_shot_result = prompt_groq(few_shot_prompt)\n",
        "print(\"Few-Shot Result:\\n\", few_shot_result)\n",
        "print(\"-----------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOO8M_vHQaKQ",
        "outputId": "47108e97-4b6c-46d1-f5e8-0ff99b86009c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "Chain of Thought Result:\n",
            " Let's break it down step by step:\n",
            "\n",
            "1. The train travels at 60 km/h for 2 hours:\n",
            "\n",
            "Distance = Speed x Time\n",
            "= 60 km/h x 2 hours\n",
            "= 120 km\n",
            "\n",
            "So, the train travels 120 km in the first 2 hours.\n",
            "\n",
            "2. The train travels at 80 km/h for 3 hours:\n",
            "\n",
            "Distance = Speed x Time\n",
            "= 80 km/h x 3 hours\n",
            "= 240 km\n",
            "\n",
            "So, the train travels 240 km in the next 3 hours.\n",
            "\n",
            "3. To find the total distance traveled, add the distances traveled in each segment:\n",
            "\n",
            "Total Distance = Distance traveled in first 2 hours + Distance traveled in next 3 hours\n",
            "= 120 km + 240 km\n",
            "= 360 km\n",
            "\n",
            "Therefore, the total distance traveled by the train is 360 km.\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Chain of Thought (CoT) Prompting\n",
        "print(\"-----------------------------------------\")\n",
        "cot_prompt = \"\"\"\n",
        "A train travels at 60 km/h for 2 hours, then at 80 km/h for 3 hours.\n",
        "What is the total distance traveled? Show your calculations step by step.\n",
        "\"\"\"\n",
        "cot_result = prompt_groq(cot_prompt)\n",
        "print(\"Chain of Thought Result:\\n\", cot_result)\n",
        "print(\"-----------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sxH48c3Qe2P",
        "outputId": "1642bd64-cdfc-4136-8ebd-107f268d6028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "Graph of Thoughts Result:\n",
            " What a fascinating project! I'm excited to help design an AI debate assistant that can integrate multiple perspectives to form a well-balanced argument. Here's a proposed architecture and methodology to achieve this:\n",
            "\n",
            "**Architecture:**\n",
            "\n",
            "1. **Perspective Extraction Module**: This module will analyze the topic, identifying key economic, ethical, social, and technological perspectives.\n",
            "2. **Perspective Analysis Module**: Each perspective will be analyzed in parallel, deconstructing its underlying assumptions, core arguments, and supporting evidence.\n",
            "3. **Connection Formation Module**: This module will dynamically connect the analyzed perspectives, identifying relationships between them, and forming a coherent narrative.\n",
            "4. **Argument Generation Module**: The connected perspectives will be used to generate a well-balanced argument, including supporting evidence and logical conclusions.\n",
            "\n",
            "**Methodology:**\n",
            "\n",
            "1. **Topic Analysis**: The AI will analyze the topic, identifying key stakeholders, relevant laws, regulations, and precedents.\n",
            "2. **Perspective Identification**: The AI will identify economic, ethical, social, and technological perspectives related to the topic, using natural language processing (NLP) and machine learning (ML) techniques.\n",
            "3. **Perspective Analysis**: Each perspective will be analyzed in parallel, using a combination of:\n",
            "\t* NLP to extract relevant quotes, studies, and data\n",
            "\t* ML to identify patterns, relationships, and correlations\n",
            "\t* Expert systems to incorporate domain-specific knowledge\n",
            "4. **Connection Formation**: The AI will identify connections between the analyzed perspectives, using graph theory and network analysis. This step will help to:\n",
            "\t* Identify relationships between perspectives\n",
            "\t* Determine the strength of each connection\n",
            "\t* Form a cohesive narrative\n",
            "5. **Argument Generation**: The connected perspectives will be used to generate a well-balanced argument, including:\n",
            "\t* Supporting evidence from multiple perspectives\n",
            "\t* Logical conclusions based on the connections formed\n",
            "\t* Identification of potential counterarguments and their refutations\n",
            "\n",
            "**Key Components:**\n",
            "\n",
            "1. **Knowledge Graph**: A graph data structure will be used to represent the analyzed perspectives, connections, and relationships.\n",
            "2. **Argument Mapping**: A mapping function will be used to connect the perspectives, creating a logical flow of arguments.\n",
            "3. **Evidence Repositories**: A repository of relevant evidence, including quotes, studies, and data, will be used to support the arguments.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "1. **Well-balanced arguments**: The AI will provide a comprehensive argument, considering multiple perspectives and connections.\n",
            "2. **Improved decision-making**: The AI's output can help stakeholders make informed decisions by considering multiple perspectives.\n",
            "3. **Enhanced critical thinking**: The AI's ability to connect perspectives will encourage critical thinking and analytical skills.\n",
            "4. **Increased transparency**: The AI will provide a clear and transparent argument, making it easier to understand the reasoning behind decisions.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "1. **Perspective identification**: Accurately identifying and categorizing perspectives can be a challenging task, especially for complex or nuanced topics.\n",
            "2. **Connection formation**: Determining the strength and nature of connections between perspectives can be a complex task.\n",
            "3. **Evidence integration**: Integrating evidence from multiple perspectives while maintaining a coherent narrative can be challenging.\n",
            "4. **Bias mitigation**: Ensuring that the AI is not biased towards a particular perspective or group of perspectives is crucial.\n",
            "\n",
            "By developing an AI debate assistant that can analyze multiple perspectives and form well-balanced arguments, we can promote more informed decision-making, enhanced critical thinking, and increased transparency.\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Graph of Thought (GoT) Prompting\n",
        "print(\"-----------------------------------------\")\n",
        "got_prompt = \"\"\"\n",
        "You are designing an AI debate assistant that helps users form strong arguments on controversial topics.\n",
        "Consider multiple perspectives before generating a well-balanced argument:\n",
        "- Economic\n",
        "- Ethical\n",
        "- Social\n",
        "- Technological\n",
        "Analyze these perspectives in parallel and dynamically connect them to form a coherent response.\n",
        "\"\"\"\n",
        "got_result = prompt_groq(got_prompt)\n",
        "print(\"Graph of Thoughts Result:\\n\", got_result)\n",
        "print(\"-----------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqOdjoGOQkIG",
        "outputId": "476ab679-f3b7-4997-c7c1-4738c069e30d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "Tree of Thoughts Result:\n",
            " Let's start building our AI story generator. Here's the setup for our mystery scenario:\n",
            "\n",
            "**Welcome to Ravenswood Manor**\n",
            "\n",
            "It's a dark and stormy night in October 1923. You are the renowned detective, Emily Windsor, who has been invited to Ravenswood Manor, a grand estate nestled in the English countryside. The manor belongs to the enigmatic millionaire, Henry Ravenswood, and his family.\n",
            "\n",
            "As you arrive at the manor, you're greeted by the stern-faced butler, Jenkins, who announces that you're just in time for dinner. The evening's festivities are disrupted when a scream pierced the night air, coming from the study of Mr. Ravenswood's son, James.\n",
            "\n",
            "**The Murder**\n",
            "\n",
            "James, 25, lies dead in his study, a single bullet wound to the head. The police are baffled by the lack of evidence and motive. As the detective, it's your job to unravel the tangled web of suspects, motives, and clues to uncover the truth.\n",
            "\n",
            "**Meet the Suspects**\n",
            "\n",
            "1. **Henry Ravenswood (James' Father)**: A reclusive millionaire, rumored to have a troubled past. His business dealings have caused resentment among some of those who work for him.\n",
            "2. **Margaret Ravenswood (James' Mother)**: A charming socialite with a reputation for being manipulative. She's been known to use her charm to get what she wants.\n",
            "3. **Emily Wilson (James' Fianc√©e)**: A beautiful and ambitious young woman. Her engagement to James was a shock to many, as they were from different social classes.\n",
            "4. **Thomas Morris (James' Business Partner)**: A cunning businessman who has clashed with James over company decisions. Their partnership has been on shaky ground for months.\n",
            "5. **Jenkins (The Butler)**: A strict and reserved individual who has been working at Ravenswood Manor for years. He seems nervous and on edge.\n",
            "\n",
            "**Your First Clue**\n",
            "\n",
            "As you begin your investigation, you notice that James' study is in disarray. A broken vase on the floor catches your eye. On closer inspection, you find a small piece of paper nearby with a cryptic message:\n",
            "\n",
            "\"The truth lies in the shadows\"\n",
            "\n",
            "What would you like to do first?\n",
            "\n",
            "A) Question Henry Ravenswood about his relationship with his son\n",
            "B) Talk to Margaret Ravenswood about her husband's business dealings\n",
            "C) Investigate Emily Wilson's background and motives\n",
            "D) Review the company books with Thomas Morris\n",
            "E) Search the manor's grounds for any signs of a struggle\n",
            "\n",
            "Choose your next step to progress the investigation and reveal more clues.\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Tree of Thought (ToT) Prompting\n",
        "print(\"-----------------------------------------\")\n",
        "tot_prompt = \"\"\"\n",
        "You are building an AI story generator that creates mystery stories by gradually revealing clues.\n",
        "1. Set up a compelling mystery scenario.\n",
        "2. Introduce characters and possible suspects step by step.\n",
        "3. Reveal clues progressively, eliminating false leads.\n",
        "4. Conclude with a logical and satisfying resolution.\n",
        "\"\"\"\n",
        "tot_result = prompt_groq(tot_prompt)\n",
        "print(\"Tree of Thoughts Result:\\n\", tot_result)\n",
        "print(\"-----------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHNknc3QlBK",
        "outputId": "1bd62e1a-2a69-4ba5-8fef-ede51f64e934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "ReAct Result\n",
            " Here's the step-by-step process to retrieve and analyze the real-time stock price of Apple Inc. (AAPL):\n",
            "\n",
            "Thought: The query requires retrieving the current stock price of Apple Inc. (AAPL). To achieve this, I need to identify a reliable source for real-time stock prices.\n",
            "\n",
            "Action: search(\"real-time stock price API\")\n",
            "Observation: The search result suggests using APIs from financial websites such as Yahoo Finance, Alpha Vantage, or Quandl. For this example, I'll use Yahoo Finance.\n",
            "\n",
            "Thought: Now, I need to retrieve the current stock price of AAPL using the Yahoo Finance API.\n",
            "\n",
            "Action: search(\"AAPL stock price Yahoo Finance\")\n",
            "Observation: The search result provides a link to the Yahoo Finance webpage for AAPL, which displays the current stock price. However, to retrieve the price programmatically, I need to use the Yahoo Finance API.\n",
            "\n",
            "Thought: I'll use the Yahoo Finance API to retrieve the current stock price of AAPL.\n",
            "\n",
            "Action: search(\"Yahoo Finance API AAPL\")\n",
            "Observation: The search result provides the API endpoint and parameters required to retrieve the current stock price of AAPL. The API endpoint is `https://query1.finance.yahoo.com/v7/finance/quote?symbols=AAPL`.\n",
            "\n",
            "Thought: Now, I'll retrieve the current stock price of AAPL using the Yahoo Finance API.\n",
            "\n",
            "Action: (Assuming an API call is made to the provided endpoint)\n",
            "Observation: The API response provides the current stock price of AAPL, which is $174.95 (please note that this value may change in real-time).\n",
            "\n",
            "Verification: To verify the result, I can cross-check the stock price with other financial websites or APIs.\n",
            "\n",
            "Action: search(\"AAPL stock price Google Finance\")\n",
            "Observation: The search result displays the current stock price of AAPL on Google Finance, which is $174.95, matching the result from the Yahoo Finance API.\n",
            "\n",
            "Final Answer: The current real-time stock price of Apple Inc. (AAPL) is $174.95.\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ReAct Prompting\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"ReAct Result\\n\", react(\"Retrieve and analyze the real-time stock price of Apple Inc. (AAPL).\"))\n",
        "print(\"-----------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
